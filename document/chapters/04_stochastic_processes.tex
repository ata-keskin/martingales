% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Stochastic Processes}\label{chapter:stochastic_processes}

It wouldn't make sense to talk about martingales without introducing stochastic processes first. In standard terminology, a stochastic process is a collection of random variables defined on the same probability space. The indexing set often represents time, and each random variable in the collection corresponds to an outcome at a specific point in that set. These processes are fundamental in understanding how random processes evolve over time. 

Take the example of stock price movement, where each day's stock price is a random variable influenced by a variety of uncertain factors. This sequence of prices forms a stochastic process, describing the stock's behavior. Another instance is the Poisson process, which models events like customer arrivals at a service center. This process captures the randomness in the timing of arrivals, aiding in optimizing resource allocation and enhancing customer service. In physics, Brownian motion characterizes the unpredictable and continuous trajectory followed by particles suspended in a medium due to random collisions with surrounding molecules, which is again modelled as a stochastic process. The theory of stochastic processes is the cornerstone for analysing randomness and building models that mirror real-world uncertainties.

Keeping this in consideration, we aim to build a comprehensive foundation for a theory of stochastic process in Isabelle. Since the definition is so straightforward, it usually suffices to just consider a collection of measurable functions to make formal statements about stochastic processes. There is not much to gain from making an explicit definition on its own. Nonetheless, we must create a framework to discuss stochastic processes that can afterwards be broadened to formalize concepts like adaptedness and predictability. Locales present themselves as the solution we are looking for.

The locale system in Isabelle is useful for managing large formal developments, as it promotes modularity and reusability. It allows us to define generic theorems and structures in one place and then reuse them in multiple contexts without duplicating efforts. For instance, when defining filtered measure spaces in the following section, we will need to have an element act as the de facto bottom element of an index type. Locales allow us to easily fix such an element for this purpose.

We start with the following locale definition.

\begin{isadefinition}
{\small
\begin{lstlisting}[style=isabelle]
locale stochastic_process =
  fixes $M \; t_0$ 
    and $X$ :: "$'b \; :: \; \{$second_countable_topology, linorder_topology$\} \Rightarrow \; 'a \; \Rightarrow \; 'c$"
  assumes random_variable[measurable]: "$\bigwedge i. \; t_0 \le i \implies X \; i \in \texttt{borel\_measurable} \; M$"
\end{lstlisting}
}
\end{isadefinition}

The measure $M$ represents the underlying measure space on which the stochastic process is defined. The index $t_0$ represents the initial point in time beyond which the process $X$ should be defined. As such, this locale formalizes a stochastic process defined on the interval $[t_0, \infty)$. 

We have the following lemmas to introduce ``constant'' stochastic processes.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma stochastic_process_const_fun:
  assumes "$f \in \texttt{borel\_measurable} \; M$"
  shows "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda \_. \; f)$"
  using assms by (unfold_locales)

lemma stochastic_process_const:
  shows "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda i \; \_. \; c \; i)$" 
  by (unfold_locales) simp

\end{lstlisting}
}
\end{isalemma}

For sake of completeness, we also provide the following collection of lemmas which show that stochastic processes are stable under various operations on a vector space.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma compose:
  assumes "$\bigwedge i. \; t_0 \le i \implies f \; i \in \texttt{borel\_measurable} \; \texttt{borel}$"
  shows "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda i \; x. \; (f \; i) \; (X \; i \; x))$"
  by (unfold_locales) (intro measurable_compose[OF random_variable assms])
  \end{lstlisting}
}
\end{isalemma}


\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma norm: "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda i \; x. \; \texttt{norm} \; (X \; i \; x))$" 
  by (fastforce intro: compose)
  \end{lstlisting}
}
\end{isalemma}

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma scaleR_right:
  assumes "$\texttt{stochastic\_process} \; M \; t_0 \; Y$"
  shows "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda i \; x. \; (Y \; i \; x) \; \cdot_R (X \; i \; x))$"
  using stochastic_process.random_variable[OF assms] random_variable 
  by (unfold_locales) simp

lemma scaleR_right_const_fun: 
  assumes "$f \in \texttt{borel\_measurable} \; M$" 
  shows "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda i \; x. \; f \; x \cdot_R (X \; i \; x))$" 
  by (unfold_locales) (intro borel_measurable_scaleR assms random_variable)

lemma scaleR_right_const: "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda i \; x. \; c \; i \cdot_R (X \; i \; x))$"
  by (unfold_locales) simp
\end{lstlisting}
}
\end{isalemma}


\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma add:
  assumes "$\texttt{stochastic\_process} \; M \; t_0 \; Y$"
  shows "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda i \; x. \; X \; i \; x + Y \; i \; x)$"
  using stochastic_process.random_variable[OF assms] random_variable 
  by (unfold_locales) simp
\end{lstlisting}
}
\end{isalemma}

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma diff:
  assumes "$\texttt{stochastic\_process} \; M \; t_0 \; Y$"
  shows "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda i \; x. \; X \; i \; x - Y \; i \; x)$"
  using stochastic_process.random_variable[OF assms] random_variable 
  by (unfold_locales) simp
\end{lstlisting}
}
\end{isalemma}

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma uminus: "$\texttt{stochastic\_process} \; M \; t_0 \; (-X)$" using scaleR_right_const[of "$\lambda \texttt{\_}. \; -1$"] 
	by (simp add: fun_Compl_def)
\end{lstlisting}
}
\end{isalemma}

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma partial_sum: "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda n \; x. \; \sum{i\in\{t_0..\texttt{<}n\}}. \; X \; i \; x)$" 
	by (unfold_locales) simp

lemma partial_sum': "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda n \; x. \; \sum{i\in\{t_0..n\}}. \; X \; i \; x)$" 
	by (unfold_locales) simp
\end{lstlisting}
}
\end{isalemma}

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]

lemma stochastic_process_sum:
  assumes "$\bigwedge i. \; i \in I \implies \texttt{stochastic\_process} \; M \; t_0 \; (X \; i)$"
  shows "$\texttt{stochastic\_process} \; M \; t_0 \; (\lambda k x. \; \sum i \in I. \; X \; i \; k \; x)$" 
  using assms[THEN stochastic_process.random_variable] by (unfold_locales, auto)

\end{lstlisting}
}
\end{isalemma}

We also specify the following sublocales to easily make statements about discrete-time and continuous-time stochastic processes.

\begin{isadefinition}
{\small
\begin{lstlisting}[style=isabelle]
locale nat_stochastic_process = stochastic_process $M$ "0 :: nat" $X$ for $M \; X$
locale real_stochastic_process = stochastic_process $M$ "0 :: real" $X$ for $M \; X$
\end{lstlisting}
}
\end{isadefinition}

By explicitly designating an element $t_0$ to be the bottom element, we can formalize continuous-time stochastic processes, i.e. $(X_t)_{t \in \mathbb{R}_{\ge 0}}$, without the need for introducing a new type for non-negative real numbers. 

\begin{remark}
Moving forward, we will define the concepts of adaptedness, progressive measurability and predictability. In our formalization, we have introduced analogous lemmas and sublocales for these process varieties as well. To avoid repeating ourselves, we will only reiterate these statements, if the proofs become non-trivial or if the assumptions change.
\end{remark}

Before presenting the remaining process varities, we must introduce the concept of a filtered measure space.

\section{Filtered Measure Spaces}

A filtered measure space is a measure space equipped with a sequence of increasing sub-$\sigma$-algebras, called a \textit{filtration} that represents the accumulation of information over time.

Concretely, let $M$ be a measure space. Assume we have a sequence of sigma-algebras $(F_n)_{n \in \mathbb{N}}$ where 
\[
	F_0 \subseteq F_1 \subseteq F_2 \subseteq \dots
\]
This sequence forms a filtration on $M$. Intuitively, each $F_n$ represents the information available up to time $n$. In general, the index set does not need to be countable. We only need it to be totally ordered, so that two indices are always comparable with one another. In Isabelle, we define the following locale to capture this concept.

\begin{isadefinition}
{\small
\begin{lstlisting}[style=isabelle]
locale filtered_measure = 
  fixes $M \; F$ and $t_0$ :: "$'b \; :: \; \{$second_countable_topology, linorder_topology$\}$"
  assumes subalgebra: "$\bigwedge i. \; t_0 \le i \implies \texttt{subalgebra} \; M \; (F \; i)$"
      and sets_F_mono: "$\bigwedge i \; j. \; t_0 \le i \implies i \le j \implies \texttt{sets} \; (F \; i) \subseteq \texttt{sets} \; (F \; j)$"
\end{lstlisting}

with the predicate \texttt{subalgebra} in \texttt{HOL-Probability.Conditional\_Expectation} defined via

\begin{lstlisting}[style=isabelle]
definition subalgebra::"$'a \; \texttt{measure} \; \Rightarrow 'a \; \texttt{measure} \; \Rightarrow \texttt{bool}$" where
  "$\texttt{subalgebra} \; M \; F = ((\texttt{space} \; F = \texttt{space} \; M) \wedge (\texttt{sets} \; F \subseteq \texttt{sets} \; M))$"
  \end{lstlisting}
}
\end{isadefinition}

\begin{remark}
	In Isabelle the $\texttt{measure}$ type is used to represent both measure spaces and $\sigma$-algebras. The latter is achieved by only considering the underlying $\sigma$-algebra via the projection \texttt{sets}.
\end{remark}

In general, a type with an ordering does not necessarily inhabit a bottom element, i.e. an element that is lesser than any other element. In the next section, we will see how the existence of a bottom element lets us make easy statements about what constitutes an adapted process and what not. From a practical point of view, this is not too much to assume, since all random processes one encounters in the real world must start at some fixed point in time (or at least that assumption can be made for practical purposes).

The keen reader might have noticed that we need a little bit more to define martingales properly. Namely, the sub-$\sigma$-algebras that comprise the filtration $(F_n)_{n \in \mathbb{N}}$ must all be $\sigma$-finite. Otherwise, we can't make use of our lemmas concerning the conditional expectation. We introduce the following locale to adress this issue.

\begin{isadefinition}
{\small
\begin{lstlisting}[style=isabelle]
locale sigma_finite_filtered_measure = filtered_measure +
  assumes sigma_finite: "sigma_finite_subalgebra $M \; (F \; t_0)$"
  \end{lstlisting}
}
\end{isadefinition}

\begin{remark}
	Since we artifically designated an element $t_0$ to represent the least index in consideration, we only need to show $\sigma$-finiteness for the sub-$\sigma$-algebra $F_{t_0}$. $\sigma$-finiteness of all other sub-$\sigma$-algebras follows from the monotonicity of the filtration.
\end{remark}

For the sake of completeness, we also introduce a local covering the case where the measure space is finite.

\begin{isadefinition}
{\small
\begin{lstlisting}[style=isabelle]
locale finite_filtered_measure = filtered_measure + finite_measure

sublocale finite_filtered_measure $\subseteq$ sigma_finite_filtered_measure 
  using subalgebra by (unfold_locales, 
  					   blast, 
					   meson dual_order.refl finite_measure_axioms finite_measure_def 
							 finite_measure_restr_to_subalg subalgebra
							 sigma_finite_measure.sigma_finite_countable)

  \end{lstlisting}
}
\end{isadefinition}


In order to make the ideas in this section a bit more concrete, we present the following two filtrations as examples.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma filtered_measure_constant_filtration:
  assumes "$\texttt{subalgebra} \; M \; F$"
  shows "$\texttt{filtered\_measure} \; M \; (\lambda \_. \; F) \; t_0$"
  using assms by (unfold_locales) (auto simp add: subalgebra_def)

sublocale sigma_finite_subalgebra $\subseteq$ constant_filtration: 
		sigma_finite_filtered_measure $M$ "$(\lambda$_. $F$)" $t_0$
  using subalg by (unfold_locales) (auto simp add: subalgebra_def)
\end{lstlisting}
}
\end{isalemma}

If we have some sub-$\sigma$-algebra $F \subseteq \Sigma$, then we can trivially take as our filtration $F_i = F$ for all $i \in [t_0,\infty)$. If we additionally know that we are working with a $\sigma$-finite subalgebra, then this yields a trivial $\sigma$-finite filtration on $M$. This choice of filtration is called a \textbf{constant filtration}. 

\begin{remark}
	In the above lemma, both entries convey the same information. The first one is stated in terms of premises and results, the latter in the language of locales. The notion of a $\sigma$-algebra being a subalgebra is formalized via the predicate \texttt{subalgebra}. Had the formalization been done in the language of locales, we could replace the first statement with an equivalent sublocale relation.
\end{remark}

Preparing for our next example, we introduce a formalization for the notion of a $\sigma$-algebra generated by a family of functions.

\begin{isadefinition}
{\small
\begin{lstlisting}[style=isabelle]
definition sigma_gen :: "$'a \; \texttt{set} \; \Rightarrow \; 'b \; \texttt{measure} \; \Rightarrow \; ('a \; \Rightarrow \; 'b) \; \texttt{set} \; \Rightarrow \; 'a \;\texttt{measure}$" where
  "$\texttt{sigma\_gen} \; \Omega \; N \; S \equiv \texttt{sigma} \; \Omega \; (\bigcup f \in S. \; \{(f \;\text{-\textasciigrave} \; A) \; \cap \; \Omega \;\vert\; A. \; A \in N\})$"
\end{lstlisting}
}
\end{isadefinition}

Given two measure spaces $(V, \mathcal{A})$ and $(W, \mathcal{B})$, it is a well known fact that a function $f : V \rightarrow W$ is measurable, if and only if the generated $\sigma$-algebra $\sigma(f)$ is a subalgebra of $\mathcal{A}$. This result is captured for families of functions in the following lemma.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma measurable_family_iff_contains_sigma_gen:
  shows "$(S \subseteq M \rightarrow_M N) \longleftrightarrow S \subseteq (\texttt{space}\; M \rightarrow \;\texttt{space}\; N) \wedge \texttt{sigma\_gen} \; (\texttt{space}\; M) \; N \; S \subseteq M$"
  $\dots$
\end{lstlisting}
}
\end{isalemma}

Now, we can introduce our more interesting example, the \textbf{natural filtration}.

\begin{isadefinition}
{\small
\begin{lstlisting}[style=isabelle]
definition natural_filtration :: "$'a \; \texttt{measure} \; \Rightarrow \; 'b \; \Rightarrow \; ('b \; \Rightarrow \; 'a \; \Rightarrow \; 'c ) \; \Rightarrow \; 'b \; \Rightarrow \; 'a \; \texttt{measure}$" where
  "$\texttt{natural\_filtration} \; M \; t_0 \; Y = (\lambda t. \; \texttt{sigma\_gen} \; (\texttt{space} \; M) \; \texttt{borel} \; \{Y \; i \; \vert\; i. \; i \in \{t_0..t\}\})$"
\end{lstlisting}
}
\end{isadefinition}
The natural filtration with respect to a stochastic process $Y$ is the filtration generated by all events involving the process up to the time index $t$, i.e. $F_t = \sigma(\{Y_i \; \vert\; i. \; i¸ \le t\})$. Assuming that $Y$ is a stochastic process, i.e. $Y_i$ is $M$-measurable for all $i \ge t_0$, the definition indeed provides a filtration. The following sublocale relation formalizes this.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
sublocale stochastic_process $\subseteq$ filtered_measure_natural_filtration: 
	filtered_measure $M$ "natural_filtration $M$ $t_0$ $X$" $t_0$
    by (unfold_locales) (intro subalgebra_natural_filtration, 
						 simp only: sets_natural_filtration, 
						 intro sigma_sets_subseteq, force) 
\end{lstlisting}
}
\end{isalemma}

The natural filtration contains information concerning the process's past behavior at each point in time. The natural filtration is essentially the simplest filtration for studying a process. However, the natural filtration is not always $\sigma$-finite. In order to show that the natural filtration give rise to a sigma finite filtered measure, we need to provide a countable exhausting set in the preimage of $X_{t_0}$.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma (in sigma_finite_measure) sigma_finite_filtered_measure_natural_filtration:
  assumes "$\texttt{stochastic\_process} \; M \; t_0 \; X$"
  and exhausting_set: "$\texttt{countable} \; A$" "$(\bigcup A) = \texttt{space} \; M$" 
		  "$\bigwedge a. \; a \in A \implies \texttt{emeasure} \; M \; a \neq \infty$" 
		  "$\bigwedge a. \; a \in A \implies \exists b \in \texttt{borel}. \; a = ((X \; t_0) \; \text{-\textasciigrave} \; b) \; \cap \; \texttt{space} \; M$"
  shows "$\texttt{sigma\_finite\_filtered\_measure} \; M \; (\texttt{natural\_filtration} \; M \; t_0 \; X) \; t_0$"
  $\dots$
\end{lstlisting}
}
\end{isalemma}

Of course, if the measure is already finite, the filtered measure space is also finite.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma (in finite_measure) finite_filtered_measure_natural_filtration:
  assumes "$\texttt{stochastic\_process} \; M \; t_0 \; X$"
  shows "$\texttt{finite\_filtered\_measure} \; M \; (\texttt{natural\_filtration} \; M \; t_0 \; X) \; t_0$"
  $\dots$
\end{lstlisting}
}
\end{isalemma}

This concludes our development of filtered measure spaces.

\section{Adapted Processes}

We call a stochastic process $(X_t)_{t \in [t_0, \infty)}$ is \textit{adapted to the filtration $(F_t)_{t \in [t_0, \infty)}$} if, for every index $t \ge t_0$, the random variable $X_t$ is measurable with respect to the $\sigma$-algebra $F_t$. This means that the value of $X_t$ depends only on the information available up to time $t$. In other words, the process ``adapts'' to the information in a way that it cannot anticipate future values based on events that have not occurred yet. We introduce the following locale.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
locale adapted_process = filtered_measure $M$ $F$ $t_0$ for $M$ $F$ $t_0$ 
	and $X$ :: "$\_ \; \Rightarrow \; \_ \; \Rightarrow \; \_ :: \; \{$second_countable_topology, banach$\}$" $+$
  assumes adapted[measurable]: "$\bigwedge i. \; t_0 \le i \implies X \; i \in \texttt{borel\_measurable} \; (F \; i)$"
\end{lstlisting}
}
\end{isalemma}

The properties we have shown concerning stochastic processes also hold for adapted processes. Although in some cases, for example in the following statement, we need to modify the measurability assumptions we make. Here, we see how constraining ourselves to an index set bounded from below helps make the assumption simpler.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma (in filtered_measure) adapted_process_const_fun:
  assumes "$f \in \texttt{borel\_measurable} \; (F \; t_0)$"
  shows "$\texttt{adapted\_process} \; M \; F \; t_0 \; (\lambda \_. \; f)$"
  $\dots$
\end{lstlisting}
}
\end{isalemma}

Furthermore, in the presence of a discrete index set, we have the following additional lemma concerning partial sums.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma (in nat_adapted_process) partial_sum_Suc: 
	"$\texttt{nat\_adapted\_process} \; M \; F \; (\lambda n \; x. \sum i<n. \; X \; (\texttt{Suc} \; i) \; x)$" 
proof (unfold_locales)
  fix $i$
  have "$X \; j \in \texttt{borel\_measurable} \; (F \; i)$" if "$j \le i$" for $j$ using that adaptedD by blast
  thus "$(\lambda x. \; \sum i<n. \; X \; (\texttt{Suc} \; i) \; x) \in \texttt{borel\_measurable} \; (F \; i)$" by auto
qed
\end{lstlisting}
}
\end{isalemma}

An adapted process is necessarily a stochastic process. This follows directly from the fact that $F_t \subseteq \Sigma$ for all $t \ge t_0$.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
sublocale adapted_process $\subseteq$ stochastic_process 
  using measurable_from_subalg subalgebra adapted by (unfold_locales) blast

sublocale nat_adapted_process $\subseteq$ nat_stochastic_process ..
sublocale real_adapted_process $\subseteq$ real_stochastic_process ..
\end{lstlisting}
}
\end{isalemma}


In the other direction, a stochastic process is always adapted to the natural filtration it generates.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
sublocale stochastic_process $\subseteq$ adapted_natural: 
	adapted_process $M$ "natural_filtration $M$ $t_0$ $X$" $t_0$ $X$ 
  by (unfold_locales) (auto simp add: natural_filtration_def 
  					   intro: random_variable measurable_sigma_gen) 
\end{lstlisting}
}
\end{isalemma}

Adapted processes are cruicial for defining martingales. A martingale is by definition an adapted process. In the following section, we will explore progressively measurable processes, even though they are not directly relevant to our formalization of martingales. This serves two purposes: first, to replicate the corresponding results on \textsf{mathlib}, and second, to establish a solid foundation for future projects to build upon.

\section{Progressively Measurable Processes}

The definition of a progressively measurable process is more intricate.

\begin{definition}
	Let $(F_t)_{t \in [t_0, \infty)}$ be a filtration of the measure space $M$. A stochastic process $(X_t)_{t \in [t_0, \infty)}$ is called progressively measurable (or simply \textit{progressive}) if, for every index $t \ge t_0$, the map $[t_0, t] \times \Omega \rightarrow E$ defined by $(i, w) \mapsto X_i(w)$ is measurable with respect to the $\sigma$-algebra $\mathcal{B}([t_0, t]) \otimes F_t$. Here $\mathcal{B}([t_0, t])$ denotes the Borel $\sigma$-algebra on $[t_0, t]$ induced by the order topology.
\end{definition}

The formalized version is as follows.

\begin{isadefinition}
{\small
\begin{lstlisting}[style=isabelle]
locale progressive_process = filtered_measure $M$ $F$ $t_0$ for $M$ $F$ $t_0$
	and $X$ :: "$\_ \; \Rightarrow \; \_ \; \Rightarrow \; \_ :: \; \{$second_countable_topology, banach$\}$" $+$
  assumes progressive[measurable]: "$\bigwedge t. \; t_0 \le t$
	$\implies (\lambda (i, x). \; X \; i \; x) \in \texttt{borel\_measurable} \; (\texttt{restrict\_space} \; \texttt{borel} \; \{t_0..t\} \otimes_M (F \; t))$"
\end{lstlisting}
}
\end{isadefinition}

Notice that the measurability assumption we make here is on the entire map $(i, w) \mapsto X_i(w)$ instead of being ``pointwise'' as in the previous two sections. As a side effect, the stochastic process defined by $X_i = c(i)$ for some $c : [t_0, \infty) \rightarrow E$ is progressively measurable, only if the function $c$ is Borel measurable. Previously, this assumption was not required.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma (in filtered_measure) progressive_process_const:
  assumes "$c \in \texttt{borel\_measurable} \; \texttt{borel}$"
  shows "$\texttt{progressive\_process} \; M \; F \; t_0 \; (\lambda i \; \_. \; c \; i)$"
  using assms by (unfold_locales) 
				 (auto simp add: measurable_split_conv 
				  intro!: measurable_compose[OF measurable_fst] 
				  measurable_restrict_space1)
  \end{lstlisting}
}
\end{isalemma}

Similarly, we must modify the premise of the lemma \texttt{compose} in order to reflect this change.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma compose:
  assumes "$(\lambda (i, x). \; f \; i \; x) \in \texttt{borel\_measurable} \; \texttt{borel}$"
  shows "$\texttt{progressive\_process} \; M \; F \; t_0 \; (\lambda i \; x. \; (f \; i) \; (X \; i \; x))$"
  $\dots$
  \end{lstlisting}
}
\end{isalemma}

A progressively measurable process is necessarily adapted. The proof is trivial and arises from the fact that the injection $y \mapsto (t, y)$ is measurable as a function $\Omega \rightarrow [t_0, t] \times \Omega$ for fixed $t \ge t_0$.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
sublocale progressive_process $\subseteq$ adapted_process 
  using measurable_compose_rev[OF progressive measurable_Pair1'] 
  unfolding prod.case by (unfold_locales) simp
\end{lstlisting}
}
\end{isalemma}

On a more interesting note, progressive measurability is equivalent to adaptedness in the discrete setting. The following lemma demonstrates this.

\begin{lemma}
	Let $(X_i)_{i \in \mathbb{N}}$ be an adapted process with respect to the filtration $(F_i)_{i \in \mathbb{N}}$. Then it is also progressively measurable.
\end{lemma}
\begin{proof}
	Let $S$ be an open set in $E$. Then $X_j^{-1}(S) \in F_i$ for all $j \le i \in \mathbb{N}$, since $(X_i)_{i \in \mathbb{N}}$ is adapted by assumption. Let $\psi : \{0,\dots,i\} \times \Omega \rightarrow E$ with $\psi(j,x) = X_j(x)$. Then, we have
	\[
		\psi^{-1}(S) \cap \{j\} \times \Omega = \{j\} \times X_j^{-1}(S) \in \mathcal{B}(\{0,\dots,i\}) \otimes F_i
	\]
	since the order topology on $\mathbb{N}$ is discrete. Furthermore
	\[
		\psi^{-1}(S) = \bigcup_{j \le i} \psi^{-1}(S) \cap \{j\} \times \Omega 
	\]
	Since the set $\{0,\dots,i\}$ is countable, it follows that $\psi^{-1}(S) \in \mathcal{B}(\{0,\dots,i\}) \otimes F_i$, since it is expressable as the union of a countable family of measurable sets.
\end{proof}

Subsequently we express this fact in the language of locales.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
sublocale nat_adapted_process $\subseteq$ nat_progressive_process
  $\dots$
\end{lstlisting}
}
\end{isalemma}

Now comes the most challenging portion of this chapter.

\section{Predictable Processes}

Before defining predictable processes in full generality, we will introduce them in the discrete setting, where the definition is easier to grasp.

\begin{definition}
	A discrete-time stochastic process $(X_i)_{i\in\mathbb{N}}$ is called \textit{predictable} with respect to a filtration $(F_i)_{i\in\mathbb{N}}$, if $X_{i + 1}$ is $F_i$-measurable for all $i \in \mathbb{N}$.
\end{definition}

This means that the value of the process in the future, $X_{i+1}$, can be ``predicted'' using the information available up to time $i$. This definition is a special case of the following more general definition for arbitrary index sets.

\begin{definition}
	Let $(F_t)_{t\in[t_0, \infty)}$ be a filtration of the measure space $M$. We define the \textit{predictable $\sigma$-algebra} $\Sigma_P$ as follows.
	\[
		\Sigma_P = \sigma(\{(s,t] \times A \;\vert\; A \in F_s \;\wedge\; t_0 \le s \;\wedge\; s < t \} \cup \{\{t_0\} \times A \;\vert\; A \in F_{t_0}\})
	\]
	A stochastic process $(X_t)_{t\in[t_0, \infty)}$ is called \textit{predictable} if the map $[t_0, \infty) \times \Omega \rightarrow E$ defined by $(t,x) \mapsto X_t(x)$ is measurable with respect to this $\sigma$-algebra.
\end{definition}

At first glance, it is difficult to make intuitive sense of this definition. Investigating properties of predictable processes in arbitrary settings is well beyond the scope of this thesis. However, we will make the following remark.

\begin{remark}
	One can show that the $\sigma$-algebra $\Sigma_P$ coincides with the $\sigma$-algebra generated by all left-continuous adapted processes. A stochastic process is called left-continuous, if the sample paths $t \mapsto X_t(x)$ are left-continuous for $\mu$-almost all $x \in \Omega$. Right-continuity is similarly defined.
\end{remark}

The corresponding locale is easy to define.

\begin{isadefinition}
{\small
\begin{lstlisting}[style=isabelle]
locale predictable_process = filtered_measure $M$ $F$ $t_0$ for $M$ $F$ $t_0$
	and $X$ :: "$\_ \; \Rightarrow \; \_ \; \Rightarrow \; \_ :: \; \{$second_countable_topology, banach$\}$" $+$
  assumes progressive[measurable]: "$(\lambda (t, x). \; X \; t \; x) \in \texttt{borel\_measurable} \; \Sigma_P$"
\end{lstlisting}
}
\end{isadefinition}

In the previous section, our results concerning progressively measurable processes all made use of the fact that the projection functions $\pi_1 : [t_0, \infty) \times \Omega \rightarrow [t_0, \infty)$ and $\pi_2 : [t_0, \infty) \times \Omega \rightarrow \Omega$ are measurable with respect to the underlying $\sigma$-algebra. In that setting, this was a triviality, since the $\sigma$-algebra in question was the product $\sigma$-algebra $\mathcal{B}([t_0, t]) \otimes F_t$ for some $t \ge t_0$, which has many nice properties. We wish to show a similar statement for the projection functions $\pi_i$ when $[t_0, \infty) \times \Omega$ is equipped with the $\sigma$-algebra $\Sigma_P$. We have come up with a sufficient condition on the index set $[t_0, \infty)$ that guarantees this.

\begin{lemma}
	Assume there exists some countable family of sets $\mathcal{I} \subseteq \{(s, t] \;\vert\; t_0 \le s \;\wedge\; s < t\}$ such that $(t_0, \infty) \subseteq (\bigcup \mathcal{I})$. Let $\pi_1 : [t_0, \infty) \times \Omega \rightarrow [t_0, \infty)$ and $\pi_2 : [t_0, \infty) \times \Omega \rightarrow \Omega$ be projections onto respective components. Then, $\pi_1$ is $\Sigma_P$-Borel-measurable and $\pi_2$ is $\Sigma_P$-$F_{t_0}$-measurable.
\end{lemma}
\begin{proof}
	We first show that $\pi_1$ is $\Sigma_P$-Borel-measurable.
	
	$\pi_1$ is trivially $(\mathcal{B}([t_0,\infty)) \otimes \sigma(\varnothing))$-Borel-measurable. Hence, if we can show 
	\[
		(\mathcal{B}([t_0,\infty)) \otimes \sigma(\varnothing)) \subseteq \Sigma_P
	\]
	then this implies that $\pi_1$ is $\Sigma_P$-Borel-measurable. For this, we will show that the Borel $\sigma$-algebra $\mathcal{B}([t_0,\infty))$ coincides with the $\sigma$-algebra generated by the set $\{(s,t] \;\vert\; t_0 \le s \;\wedge\; s < t\}$.
	
	Since the ordering on $[t_0, \infty)$ is linear, the set of open rays $\{(s,\infty) \;\vert\; s \ge t_0\}$ generates the order topology on $\mathcal{B}([t_0,\infty))$. This also depends on the premise that the order topology is second-countable. Let $c \ge t_0$. We have
	\begin{align*}
		(c, \infty) &= (c, \infty) \cap (\bigcup \mathcal{I}) \\
		&= (\bigcup_{I \in \mathcal{I}} I \cap (c, \infty))
	\end{align*}
	From the assumptions, we know that 
	\[
		I \cap (c, \infty) \in \{(s, t] \;\vert\; t_0 \le s \;\wedge\; s < t\}
	\]
	for $I \in \mathcal{I}$. Hence $(c, \infty) \in \sigma(\{(s,t] \;\vert\; t_0 \le s \;\wedge\; s < t\})$, since $\mathcal{I}$ is countable.
	In the other direction, any interval $(s,t]$ with $s \ge t_0$ is obviously $\mathcal{B}([t_0,\infty))$-measurable. Thus, the $\sigma$-algebras indeed coincide. This completes the first part of the proof.
	
	Next, we show that $\pi_2$ is $\Sigma_P$-$F_{t_0}$-measurable.
	Let $S \in F_{t_0}$. We have
	\[
		\pi_2^{-1}(S) = [t_0, \infty) \times S
	\]
	The assumptions already imply $(t_0, \infty) = (\bigcup \mathcal{I})$. Furthermore $S \in F_t$ for all $t \ge t_0$. Hence, we have
	\[
		(t_0, \infty) \times S = (\bigcup \mathcal{I}) \times S \in \Sigma_P \;\;\textrm{and}\;\; \{t_0\} \times S \in \Sigma_P
	\]
	which together imply $[t_0, \infty) \times S \in \Sigma_P$.
\end{proof}

\begin{remark}
	Our formal proof for the $\Sigma_P$-Borel-measurability of $\pi_1$ follows an alternative path to the one given here. The lemma \texttt{borel\_Ioi} establishes that the Borel $\sigma$-algebra  $\mathcal{B}$ on the entire space is generated by open rays. We then consider the restricted $\sigma$-algebra $\mathcal{B}([t_0,\infty))$, which is defined in Isabelle as
	\[
		\mathcal{B}([t_0,\infty)) = \sigma\left(\left\{[t_0, \infty) \cap A \;\vert\; A \in \mathcal{B}\right\}\right)
	\]
	Together with \texttt{borel\_Ioi} this yields
	\[
	 	\mathcal{B}([t_0,\infty)) = \sigma\left(\left\{[t_0, \infty) \cap A \;\vert\; A \in \sigma(\{(s,\infty) \;\vert\; s \in (-\infty,\infty)\})\right\}\right)
	\]
	In our formalization, we show that this $\sigma$-algebra on the right hand side is equal to $\sigma(\{(s,t] \;\vert\; t_0 \le s \;\wedge\; s < t\})$.
	
	On a different note, we believe strongly that $\pi_2$ is not $\Sigma_P$-$F_t$-measurable for $t > t_0$ in general, or at least our condition is not sufficient to show this. This stems from the fact that $\pi_2^{-1}(S) = [t_0, \infty) \times S$ and the element $t_0$ can only originate from some set in $\{\{t_0\} \times A \;\vert\; A \in F_{t_0}\}$. However, in general $F_t \not\subseteq F_{t_0}$.
\end{remark}

In the discrete-time case, the family $\mathcal{I} = \{\{n + 1\}\}_{n \in \mathbb{N}}$ fulfills this condition. Similarly, in the continous-time case we can use $\mathcal{I} = \{(0,n + 1]\}\}_{n \in \mathbb{N}}$. The following lemmas in Isabelle reflect this.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma (in nat_filtered_measure) measurable_predictable_sigma_snd:
  shows "$\texttt{snd} \; \in \Sigma_P \rightarrow_M F \; 0$"
  by (intro measurable_predictable_sigma_snd[of "$\texttt{range} \; (\lambda x. \; \{\texttt{Suc} \; x\})$"]) 
	 (force | simp add: greaterThan_0)+

lemma (in nat_filtered_measure) measurable_predictable_sigma_fst:
  shows "$\texttt{fst} \; \in \Sigma_P \rightarrow_M \texttt{borel}$"
  by (intro measurable_predictable_sigma_fst[of "$\texttt{range} \; (\lambda x. \; \{\texttt{Suc} \; x\})$"]) 
	 (force | simp add: greaterThan_0)+
\end{lstlisting}
}
\end{isalemma}

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma (in real_filtered_measure) measurable_predictable_sigma_snd:
  shows "$\texttt{snd} \; \in \Sigma_P \rightarrow_M F \; 0$"
  using real_arch_simple 
  by (intro measurable_predictable_sigma_snd[of "$\texttt{range} \; (\lambda x::\texttt{nat}. \; \{0\texttt{<}..\texttt{real} \; (\texttt{Suc} \; x)\})$"]) 
	 (fastforce intro: add_increasing)+

lemma (in real_filtered_measure) measurable_predictable_sigma_fst:
  shows "$\texttt{fst} \; \in \Sigma_P \rightarrow_M \texttt{borel}$"
  using real_arch_simple 
  by (intro measurable_predictable_sigma_fst[of "$\texttt{range} \; (\lambda x::\texttt{nat}. \; \{0\texttt{<}..\texttt{real} \; (\texttt{Suc} \; x)\})$"])
	 (fastforce intro: add_increasing)+
\end{lstlisting}
}
\end{isalemma}

These measurability results concerning projections are necessary to show the following statements about ``constant'' processes being predictable.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma (in filtered_measure) predictable_process_const_fun:
  assumes "$\texttt{snd} \; \in \Sigma_P \rightarrow_M F \; t_0$" "$f \in \texttt{borel\_measurable} \; (F \; t_0)$"
  shows "$\texttt{predictable\_process} \; M \; F \; t_0 \; (\lambda\_. \; f)$"
  using measurable_compose_rev[OF assms(2)] assms(1) 
  by (unfold_locales) (auto simp add: measurable_split_conv)
\end{lstlisting}
}
\end{isalemma}

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
lemma (in filtered_measure) predictable_process_const:
  assumes "$\texttt{fst} \; \in \texttt{borel\_measurable} \; \Sigma_P$" "$c \in \texttt{borel\_measurable} \; \texttt{borel}$"
  shows "$\texttt{predictable\_process} \; M \; F \; t_0 \; (\lambda i \_. \; c \; i)$"
  using assms by (unfold_locales) (simp add: measurable_split_conv)
\end{lstlisting}
}
\end{isalemma}

We will now show that a predictable process is necessarily progressively measurable.

\begin{lemma}
	A predictable process $(X_t)_{t \in [t_0,\infty)}$ is also progressively measurable.
\end{lemma}
\begin{proof}
	Let $i \ge t_0$. Let $\iota$ denote the identity function, restricted to the domain $[t_0, i] \times \Omega$, i.e. $\iota = \texttt{id}\vert_{[t_0,t]}$. We aim to show that $\iota$ is $(\mathcal{B}([t_0,i]) \otimes F_i)$-$\Sigma_P$-measurable. The statement follows simply from definitions of predictability and progressive measurability.
	
	For any $S$ in the generating set of $\Sigma_P$, we will show that $\iota^{-1}(S) \in \mathcal{B}([t_0,i]) \otimes F_i$. This is enough to show the required measurability.
	
	First, let $S = \{t_0\} \times A$ for some $A \in F_{t_0}$.
	Then
	\[
		\iota^{-1}(S) = \{t_0\} \times A \in \mathcal{B}([t_0,i]) \otimes F_i
	\]
	since $\{t_0\}$ is closed and $F_{t_0} \subseteq F_i$.
	
	Next, let $S = (s,t] \times A$ for some $A \in F_s$ and $s, t \ge t_0$ with $s < t$.
	Then
	\[
		\iota^{-1}(S) = (s, \min(i, t)] \times A
	\]
	
	Assume $s \le i$. Then $A \in F_i$. Furthermore, $(s, \min(i, t)] \in \mathcal{B}([t_0,i])$ since the $\sigma$-algebra $\mathcal{B}([t_0,i])$ is generated by half-open intervals. 
	Hence, $\iota^{-1}(S) \in \mathcal{B}([t_0,i]) \otimes F_i$.
	
	Assume $s > i$. Then $\iota^{-1}(S) = \varnothing \in \mathcal{B}([t_0,i]) \otimes F_i$. This covers all cases and the proof is complete.
\end{proof}

We formalize this fact as a sublocale relation.

\begin{isalemma}
{\small
\begin{lstlisting}[style=isabelle]
sublocale predictable_process $\subseteq$ progressive_process
  $\dots$
\end{lstlisting}
}
\end{isalemma}

In the scope of our thesis, we will only use results concerning discrete-time predictable processes. We will now show that the above definitions for predictable processes coincide when the index set is $\mathbb{N}$. First we show the following lemma.

\begin{theorem}
	Let $(\bigcup_{i \in \mathbb{N}} \; \{i\} \times A_i) \in \Sigma_P$ for some collection of sets $(A_i)_{i \in \mathbb{N}}$. Then $A_0 \in F_0$ and $A_{i+1} \in F_i$ for all $i \in \mathbb{N}$.
\end{theorem}
\begin{proof}
	Consider the set 
	\[
		\mathcal{D} = \{S \in \Sigma_P \;\vert\; \forall (A_i)_{i \in \mathbb{N}}. \; S = (\bigcup_{i \in \mathbb{N}} \{i\} \times A_i) \Longrightarrow A_{i+1} \in F_i \;\wedge\; A_0 \in F_0 \}
	\]
	We will show that $\mathcal{D}$ constitutes a $\sigma$-algebra. Obviously $\varnothing \in \mathcal{D}$.
	
	Assume $S \in \mathcal{D}$. 
	
	Let $(A_i)_{i \in \mathbb{N}}$ be a family of sets with $(\mathbb{N} \times \Omega) \setminus S = (\bigcup_{i \in \mathbb{N}} \{i\} \times A_i)$. Then
	\begin{align*}
		S &= (\mathbb{N} \times \Omega) \setminus (\bigcup_{i \in \mathbb{N}} \{i\} \times A_i) \\
		&= (\bigcup_{i \in \mathbb{N}} \{i\} \times \Omega) \setminus (\bigcup_{i \in \mathbb{N}} \{i\} \times A_i) \\
		&= (\bigcup_{i \in \mathbb{N}} \{i\} \times (\Omega \setminus A_i))
	\end{align*}
	Hence, we know $\Omega \setminus A_{i+1} \in F_i$ and $\Omega \setminus A_0 \in F_0$. Therefore, $A_{i+1} \in F_i$ and $A_0 \in F_0$. We have $(\mathbb{N} \times \Omega) \setminus S \in \mathcal{D}$.
	
	Assume $S_i \in \mathcal{D}$ for $i \in \mathbb{N}$. 
	
	Let $(A_i)_{i \in \mathbb{N}}$ be a family of sets with $(\bigcup_{i \in \mathbb{N}} S_i) = (\bigcup_{i \in \mathbb{N}} \{i\} \times A_i)$. For each $S_i$, we need to find some family of sets $(B_j(i))_{j \in \mathbb{N}}$, such that $S_i = (\bigcup_{j \in \mathbb{N}} \{j\} \times B_j(i))$. Define
	\[
		B_j(i) = \pi_2(S_i \cap \{j\} \times \Omega)
	\]
	The intuition is as follows. We first select only those pairs in $S_i$, with the first component equal to $j$. Then we project onto the second component. Hence, we have the equality
	\[
		\{j\} \times B_j(i) = S_i \cap \{j\} \times \Omega
	\]
	Therefore $S_i = (\bigcup_{j \in \mathbb{N}} \{j\} \times B_j(i))$. We have $B_{j+1}(i) \in F_j$ and $B_0(i) \in F_0$. Furthermore, we know
	\begin{align*}
		A_i &= \pi_2\left((\bigcup_{j \in \mathbb{N}} S_j) \cap \{i\} \times \Omega\right) \\
		&= \bigcup_{j \in \mathbb{N}} \pi_2(S_j \cap \{i\} \times \Omega) \\
		&= \bigcup_{j \in \mathbb{N}} B_i(j)
	\end{align*}
	Hence, $A_{i + 1} \in F_i$ and $A_0 \in F_0$. Thus $\mathcal{D}$ is indeed a $\sigma$-algebra. Now we show 
	\[
		\{\{s + 1,\dots, t\} \times A \;\vert\; A \in F_s \;\wedge\; s < t \} \cup \{\{0\} \times A \;\vert\; A \in F_0\} \subseteq \mathcal{D}
	\]
	Let $S \in \{\{0\} \times A \;\vert\; A \in F_0\}$. Then $S = (\bigcup_{i \in \mathbb{N}} \{i\} \times A_i)$ implies $A_0 \in F_0$ and $A_i = \varnothing$ for $i > 0$. Hence $S \in \mathcal{D}$.
	
	Let $S = \{s + 1,\dots,t\} \times B$ with $s < t$ and $B \in F_s$ for some $s$, $t$ and $B$. Then, $S = (\bigcup_{i \in \mathbb{N}} \{i\} \times A_i)$ implies $A_i = B$ for $i \in \{s + 1,\dots,t\}$ and $A_i = \varnothing$ otherwise. Thus, $A_0 = \varnothing \in F_0$. Moreover, $A_{i + 1} = B \in F_i$ if $i \in \{s,\dots,t - 1\}$ since the subalgebras $F_i$ are nested, and $A_{i + 1} = \varnothing \in F_i$ for $i \notin \{s,\dots,t - 1\}$. Together with our previous result, this implies $\Sigma_P \subseteq \mathcal{D}$, which completes the proof.
\end{proof}

\begin{remark}
	For the proof of this lemma in Isabelle, we have used the induction scheme \texttt{sigma\_sets.induct}, since the generated $\sigma$-algebra $\sigma(\cdot)$ is defined as an inductive set in Isabelle. The proof above demonstrates that this induction scheme is equivalent to the principle of ``good-sets'' which we have utilized.
\end{remark}

We can now characterize predictability in the discrete-setting as follows.
\begin{theorem}
	A stochastic process $(X_n)_{n \in \mathbb{N}}$ is predictable, if and only if $(X_{n + 1})_{n \in \mathbb{N}}$ is adapted to the filtration $(F_n)_{n \in \mathbb{N}}$ and $X_0$ is $F_0$-measurable.
\end{theorem}
\begin{proof}
	Assume $(X_n)_{n \in \mathbb{N}}$ is predictable. Since predictable processes are also adapted, $X_0$ is $F_0$-measurable.
	
	Let $n \in \mathbb{N}$ and let $S$ be an open set. Consider the map $\psi$ defined by $\psi(i,x) = X_i(x)$. We have
	\[
		\psi^{-1}(S) \cap (\{n + 1\} \times \Omega) = \psi^{-1}(S) \cap ((n, n + 1] \times \Omega) \in \Sigma_P
	\]
	On the other hand
	\[
		\psi^{-1}(S) \cap (\{n + 1\} \times \Omega) = \{n + 1\} \times X_{n + 1}^{-1}(S)
	\]
	Applying the previous lemma for 
	\[
		A_i = 
		\begin{cases}
			X_{n + 1}^{-1}(S) &\quad \textrm{if} \; i = n + 1 \\
			\varnothing &\quad \textrm{otherwise}
		\end{cases}
	\]
	we get $X_{n + 1}^{-1}(S) \in F_n$. Hence $(X_{n + 1})_{n \in \mathbb{N}}$ is adapted to the filtration $(F_n)_{n \in \mathbb{N}}$.
	
	For the other direction, assume $(X_{n + 1})_{n \in \mathbb{N}}$ is adapted to the filtration $(F_n)_{n \in \mathbb{N}}$ and $X_0$ is $F_0$-measurable.
	
	Let $S$ be an open set. We have
	\[
		\{0\} \times X_0^{-1}(S) \in \Sigma_P
	\]
	using the definition of $\Sigma_P$ and the fact that $X_0$ is $F_0$-measurable. Similarly, for $n \in \mathbb{N}$ we have $X_{n + 1}^{-1}(S) \in F_n$. Hence
	\[
		\{n + 1\} \times X_{n + 1}^{-1}(S) = (n, n + 1] \times X_{n + 1}^{-1}(S) \in \Sigma_P
	\]
	Putting it all together, we have
	\[
		\psi^{-1}(S) = \left(\bigcup_{i \in \mathbb{N}} \{i\} \times X_i^{-1}(S) \right) \in \Sigma_P
	\]
	since $\Sigma_P$ is closed under countable unions. Thus $(X_n)_{n \in \mathbb{N}}$ is predictable.
\end{proof}

This finalizes our formalization of various types of stochastic processes in Isabelle.
